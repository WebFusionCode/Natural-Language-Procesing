{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8AbHI8d1bTD",
        "outputId": "8fee7130-5f81-4b2b-d0ec-a7fcc6bcc089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 1\n",
            "Total words: 87019\n",
            "Vocabulary size: 12131\n",
            "\n",
            "Top 10 bigrams:\n",
            "('of', 'the') : 850\n",
            "('in', 'the') : 610\n",
            "('to', 'the') : 279\n",
            "('on', 'the') : 254\n",
            "('for', 'the') : 223\n",
            "('at', 'the') : 199\n",
            "('will', 'be') : 157\n",
            "('that', 'the') : 149\n",
            "('with', 'the') : 142\n",
            "('and', 'the') : 141\n",
            "\n",
            "Top 10 trigrams:\n",
            "('one', 'of', 'the') : 44\n",
            "('mr', 'and', 'mrs') : 42\n",
            "('the', 'united', 'states') : 37\n",
            "('members', 'of', 'the') : 28\n",
            "('president', 'of', 'the') : 22\n",
            "('a', 'number', 'of') : 19\n",
            "('the', 'white', 'house') : 19\n",
            "('as', 'a', 'result') : 18\n",
            "('some', 'of', 'the') : 18\n",
            "('the', 'u', 's') : 17\n",
            "\n",
            "P('the' | 'in') = 0.30198019801980197\n",
            "P('president' | 'the','of') = 0\n",
            "\n",
            "Sentence: the president of the company\n",
            "Probability (Bigram Model): 9.05010204014703e-07\n"
          ]
        }
      ],
      "source": [
        "import nltk, re\n",
        "from nltk.corpus import brown\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download(\"brown\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "sents = brown.sents(categories=\"news\")\n",
        "txt = \" \".join([\" \".join(s) for s in sents])\n",
        "txt = txt.lower()\n",
        "txt = re.sub(r\"[^a-z\\s]\", \"\", txt)\n",
        "\n",
        "sentstk = nltk.sent_tokenize(txt)\n",
        "wordstk = nltk.word_tokenize(txt)\n",
        "\n",
        "print(\"Total sentences:\", len(sentstk))\n",
        "print(\"Total words:\", len(wordstk))\n",
        "print(\"Vocabulary size:\", len(set(wordstk)))\n",
        "\n",
        "def genngrams(tokens, n):\n",
        "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "\n",
        "uni = genngrams(wordstk, 1)\n",
        "bi = genngrams(wordstk, 2)\n",
        "tri = genngrams(wordstk, 3)\n",
        "\n",
        "bicount = Counter(bi)\n",
        "tricount = Counter(tri)\n",
        "unicount = Counter(uni)\n",
        "\n",
        "print(\"\\nTop 10 bigrams:\")\n",
        "for pair, freq in bicount.most_common(10):\n",
        "    print(pair, \":\", freq)\n",
        "\n",
        "print(\"\\nTop 10 trigrams:\")\n",
        "for triplet, freq in tricount.most_common(10):\n",
        "    print(triplet, \":\", freq)\n",
        "\n",
        "def bipro(w1, w2):\n",
        "    return bicount[(w1, w2)] / unicount[(w1,)] if unicount[(w1,)] > 0 else 0\n",
        "\n",
        "def tripro(w1, w2, w3):\n",
        "    return tricount[(w1, w2, w3)] / bicount[(w1, w2)] if bicount[(w1, w2)] > 0 else 0\n",
        "\n",
        "print(\"\\nP('the' | 'in') =\", bipro(\"in\", \"the\"))\n",
        "print(\"P('president' | 'the','of') =\", tripro(\"the\", \"of\", \"president\"))\n",
        "\n",
        "def sentprobi(sentence):\n",
        "    words = nltk.word_tokenize(sentence.lower())\n",
        "    prob = 1.0\n",
        "    for i in range(len(words)-1):\n",
        "        prob *= bipro(words[i], words[i+1])\n",
        "    return prob\n",
        "\n",
        "sentence = \"the president of the company\"\n",
        "print(\"\\nSentence:\", sentence)\n",
        "print(\"Probability (Bigram Model):\", sentprobi(sentence))"
      ]
    }
  ]
}